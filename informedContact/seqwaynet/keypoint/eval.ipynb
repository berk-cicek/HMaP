{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import robotic as ry\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from seqwaynet.keypoint.keypoint_model import NextKeypointPredictor\n",
    "from seqwaynet.dataset.keypoint_dataset import KeypointDataset\n",
    "import pathlib\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"puck_obs_move\"\n",
    "cur_dir = os.getcwd()\n",
    "output_dir = f\"{cur_dir}/output_contact/{task}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading all data:: 100%|██████████| 360/360 [00:23<00:00, 15.12it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = KeypointDataset(f\"/home/kutay/repos/ProgressiveNet/seqwaynet/data/test/keypoint/{task}/sample\", stats_file=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_config, ex_cur_contact, ex_cur_gripper, ex_next_keypoint, ex_next_gripper, ex_config_path, ex_contact_path = test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([510])\n"
     ]
    }
   ],
   "source": [
    "print(ex_config.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path: str):\n",
    "    model = NextKeypointPredictor(len(ex_config))\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    #model.cuda()\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_keypoint_with_pred(path):\n",
    "    # Extract the directory and filename parts\n",
    "    dir_name, file_name = os.path.split(path)\n",
    "    \n",
    "    # Use regex to match keypoint_X.csv and replace it with config_X.csv\n",
    "    new_file_name = re.sub(r'contacts_(\\d+)\\.csv', r'pred_\\1.csv', file_name)\n",
    "    \n",
    "    # Join the directory back with the new filename\n",
    "    new_path = os.path.join(dir_name, new_file_name)\n",
    "    \n",
    "    return new_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #criterion = nn.HuberLoss(delta=0.5)\n",
    "# mse = nn.MSELoss()\n",
    "# bce = nn.BCELoss()\n",
    "\n",
    "# def evaluate_model(model, test_dataloader):\n",
    "#     \"\"\"Evaluate the model on the test set and return the average test loss.\"\"\"\n",
    "#     model.eval()  # Set model to evaluation mode\n",
    "#     test_loss = 0.0\n",
    "\n",
    "#     with torch.no_grad():  # Disable gradient computation\n",
    "#         for batch in tqdm(test_dataloader, desc=\"Evaluating test samples:\"):\n",
    "#             input_configs, input_contacts, input_grippers, next_contacts, next_grippers, config_path, contact_path = batch\n",
    "            \n",
    "#             #print(keypoint_path)\n",
    "#             contact_config_save_path = replace_keypoint_with_pred(contact_path[0])\n",
    "\n",
    "#             input_configs = input_configs.cuda()\n",
    "#             input_contacts = input_contacts.cuda()\n",
    "#             input_grippers = input_configs.cuda()\n",
    "#             next_contacts = next_contacts.cuda()\n",
    "#             next_grippers = next_grippers.cuda()\n",
    "\n",
    "#             # Forward pass\n",
    "#             contacts, grippers = model.forward(input_configs, input_contacts, input_grippers)\n",
    "#             print(grippers)\n",
    "\n",
    "#             outputs = torch.cat((contacts, grippers), dim=1).cpu()\n",
    "#             # Compute loss\n",
    "#             mse_loss = mse(contacts, next_contacts)\n",
    "#             bce_loss = bce(grippers, next_grippers)\n",
    "#             test_loss += (mse_loss + bce_loss).item()\n",
    "\n",
    "#             grippers = torch.round(grippers)\n",
    "#             outputs = outputs.cpu()\n",
    "#             outputs = pd.DataFrame(outputs).to_csv(contact_config_save_path, header=None, index=None)\n",
    "\n",
    "#     return test_loss / len(test_dataloader)  # Return average test loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model: NextKeypointPredictor,\n",
    "    val_dataloader: DataLoader,\n",
    "    criterion_contact,\n",
    "    criterion_gripper,\n",
    "):\n",
    "    \"\"\"Evaluate the model on the validation set and return the average validation loss.\"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss_mse = 0.0\n",
    "    val_loss_bce = 0.0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch in tqdm(val_dataloader, desc=\"Validation Batches:\"):\n",
    "            (\n",
    "                input_configs,\n",
    "                contact_current,\n",
    "                gripper_idx_current,\n",
    "                contact_next,\n",
    "                gripper_idx_next,\n",
    "                config_path,\n",
    "                contact_path,\n",
    "            ) = batch\n",
    "\n",
    "            # Move data to GPU if available\n",
    "            input_configs = input_configs.cuda()\n",
    "            contact_current = contact_current.cuda()\n",
    "            contact_next = contact_next.cuda()\n",
    "            gripper_idx_current = gripper_idx_current.view(-1, 1).cuda()\n",
    "            gripper_idx_next = gripper_idx_next.view(-1, 1).cuda()\n",
    "\n",
    "            contact_config_save_path = replace_keypoint_with_pred(contact_path[0])\n",
    "            #print(contact_config_save_path)\n",
    "\n",
    "            # Forward pass\n",
    "            contact_pred, gripper_pred = model(\n",
    "                input_configs, contact_current, gripper_idx_current\n",
    "            )\n",
    "\n",
    "            # Compute losses\n",
    "            loss_contact = criterion_contact(contact_pred, contact_next)\n",
    "            loss_gripper = criterion_gripper(gripper_pred, gripper_idx_next)\n",
    "            total_loss = loss_contact + loss_gripper\n",
    "\n",
    "            val_loss_mse += loss_contact.item()\n",
    "            val_loss_bce += loss_gripper.item()\n",
    "\n",
    "            gripper_pred = torch.round(gripper_pred)\n",
    "            outputs = torch.cat((contact_pred, gripper_pred), dim=1).cpu()\n",
    "            outputs = pd.DataFrame(outputs).to_csv(contact_config_save_path, header=None, index=None)\n",
    "\n",
    "    avg_val_loss_mse = val_loss_mse / len(val_dataloader)\n",
    "    avg_val_loss_bce = val_loss_bce / len(val_dataloader)\n",
    "    avg_val_loss = avg_val_loss_mse + avg_val_loss_bce\n",
    "    return (\n",
    "        avg_val_loss,\n",
    "        avg_val_loss_mse,\n",
    "        avg_val_loss_bce,\n",
    "    )  # Return average validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NextKeypointPredictor(\n",
       "  (block1): Sequential(\n",
       "    (0): Linear(in_features=514, out_features=512, bias=True)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (block3): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (block4): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (output_contact): Linear(in_features=64, out_features=3, bias=True)\n",
       "  (output_gripper): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model(f\"{output_dir}/best_model.pth\")\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches:: 100%|██████████| 1776/1776 [00:01<00:00, 1201.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test loss: (0.006288719410375191, 0.006094471291140172, 0.0001942481192350192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "print(\"Average test loss:\", evaluate_model(model, test_dataloader, nn.MSELoss(), nn.BCELoss()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_episode(model: NextKeypointPredictor, test_dataset: KeypointDataset, ep_idx: int):\n",
    "    episode_indices = test_dataset.get_episode_indices(ep_idx)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        C = ry.Config()\n",
    "        f = C.addFrame(\"cam_frame\")\n",
    "        f.setPose(\"[-0.4, 0.1, 1, 0.0007963, -1, 0, 0]\")\n",
    "        #f.setAttribute(\"focalLength\", 0.5)  # wide angle\n",
    "        f.setAttribute(\"width\", 600)  # super wide angle\n",
    "        f.setAttribute(\"height\", 600)  # super wide angle\n",
    "        C.view_setCamera(f)\n",
    "\n",
    "        config_vec, cur_keypoint, next_keypoint_gt, config_path, _ = test_dataset[episode_indices[0]]\n",
    "        config_path = config_path.replace(\"csv\", \"g\")\n",
    "        C.addFile(config_path)\n",
    "\n",
    "        next_keypoint_ball = C.addFrame(\"next_keypoint\")\n",
    "\n",
    "        next_keypoint_ball.setShape(ry.ST.sphere, size=[0.02])\n",
    "        \n",
    "        next_keypoint_ball.setColor([1.0, 0.0, 0.0])\n",
    "\n",
    "        next_keypoint_gt_ball = C.addFrame(\"next_keypoint_gt\")\n",
    "        next_keypoint_gt_ball.setShape(ry.ST.sphere, size=[0.02])\n",
    "        next_keypoint_gt_ball.setColor([0.0, 1.0, 0.0])\n",
    "        for idx in episode_indices:\n",
    "            config_vec, cur_keypoint, next_keypoint_gt, config_path, _ = test_dataset[idx]\n",
    "            \n",
    "            #print(config_path)\n",
    "            \n",
    "            config_vec = config_vec.view(1, -1).cuda()\n",
    "            cur_keypoint = cur_keypoint.view(1, -1).cuda()\n",
    "            #print(config_vec.shape, cur_keypoint.shape)\n",
    "            next_keypoint = model.forward(config_vec, cur_keypoint)\n",
    "            next_keypoint = next_keypoint.cpu()\n",
    "\n",
    "            cur_keypoint = cur_keypoint.view(-1)\n",
    "            next_keypoint = next_keypoint.view(-1)\n",
    "            next_keypoint_gt = next_keypoint_gt.view(-1)\n",
    "\n",
    "            print(next_keypoint, next_keypoint_gt)\n",
    "\n",
    "            next_keypoint_ball.setPosition(next_keypoint.tolist()[:3])\n",
    "            next_keypoint_gt_ball.setPosition(next_keypoint_gt.tolist()[:3])\n",
    "            \n",
    "            print(cur_keypoint.shape, next_keypoint.shape, next_keypoint_gt.shape)\n",
    "\n",
    "            #C.addFile(config_path)\n",
    "            \n",
    "\n",
    "            C.view(pause=True, message=f\"Episode {ep_idx}, step {idx}\")\n",
    "        \n",
    "        C.view(pause=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvisualize_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mep_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m, in \u001b[0;36mvisualize_episode\u001b[0;34m(model, test_dataset, ep_idx)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_episode\u001b[39m(model: NextKeypointPredictor, test_dataset: KeypointDataset, ep_idx: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     episode_indices \u001b[38;5;241m=\u001b[39m \u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_episode_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mep_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/repos/ProgressiveNet/seqwaynet/dataset/keypoint_dataset.py:199\u001b[0m, in \u001b[0;36mKeypointDataset.get_episode_indices\u001b[0;34m(self, episode_index)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Given an episode index, return the indices of the corresponding data points.\"\"\"\u001b[39;00m\n\u001b[1;32m    198\u001b[0m episode_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeypoints_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 199\u001b[0m indices \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    200\u001b[0m     i\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (\n\u001b[1;32m    202\u001b[0m         config_current,\n\u001b[1;32m    203\u001b[0m         contact_current,\n\u001b[1;32m    204\u001b[0m         config_next,\n\u001b[1;32m    205\u001b[0m         contact_next,\n\u001b[1;32m    206\u001b[0m         _,\n\u001b[1;32m    207\u001b[0m         _,\n\u001b[1;32m    208\u001b[0m     ) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(config_current)) \u001b[38;5;241m==\u001b[39m episode_folder\n\u001b[1;32m    210\u001b[0m ]\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indices\n",
      "File \u001b[0;32m~/repos/ProgressiveNet/seqwaynet/dataset/keypoint_dataset.py:209\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Given an episode index, return the indices of the corresponding data points.\"\"\"\u001b[39;00m\n\u001b[1;32m    198\u001b[0m episode_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeypoints_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    199\u001b[0m indices \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    200\u001b[0m     i\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (\n\u001b[1;32m    202\u001b[0m         config_current,\n\u001b[1;32m    203\u001b[0m         contact_current,\n\u001b[1;32m    204\u001b[0m         config_next,\n\u001b[1;32m    205\u001b[0m         contact_next,\n\u001b[1;32m    206\u001b[0m         _,\n\u001b[1;32m    207\u001b[0m         _,\n\u001b[1;32m    208\u001b[0m     ) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m--> 209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_current\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m==\u001b[39m episode_folder\n\u001b[1;32m    210\u001b[0m ]\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indices\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/posixpath.py:152\u001b[0m, in \u001b[0;36mdirname\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdirname\u001b[39m(p):\n\u001b[1;32m    151\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the directory component of a pathname\"\"\"\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     sep \u001b[38;5;241m=\u001b[39m _get_sep(p)\n\u001b[1;32m    154\u001b[0m     i \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mrfind(sep) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not Tensor"
     ]
    }
   ],
   "source": [
    "visualize_episode(model, test_dataset, ep_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
